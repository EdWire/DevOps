{
    "nbformat": 4,
    "nbformat_minor": 2,
    "metadata": {
        "save_output": true,
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "execution_count": 21,
            "cell_type": "code",
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "source": [
                "instance = InstanceId = instanceId\r\n",
                "ApiUrl = apiUrl\r\n",
                "SchoolYear = schoolYear\r\n",
                "DistrictId = DistrictID = districtID = districtId\r\n",
                "apiLimit = batchLimit\r\n",
                "\r\n",
                "prepareEdFiMetaData = prepareEdFiMetadata"
            ],
            "outputs": []
        },
        {
            "execution_count": 22,
            "cell_type": "code",
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "source": [
                "import copy\r\n",
                "import pyspark.sql.functions as f"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "source": [
                "### URL Initializations"
            ],
            "outputs": []
        },
        {
            "execution_count": 23,
            "cell_type": "code",
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "source": [
                "%run OEA/modules/Ed-Fi/v0.6/src/utilities/edfi_v0_6_fetch_urls"
            ],
            "outputs": []
        },
        {
            "execution_count": 24,
            "cell_type": "code",
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "source": [
                "instance_id = instanceId\r\n",
                "school_year = schoolYear\r\n",
                "api_url = apiUrl\r\n",
                "\r\n",
                "edfi_api_manager = EdFiApiManager(api_url, instance_id, school_year)\r\n",
                "edfi_api_manager.update_urls()\r\n",
                "edfi_api_manager.set_other_metadata()\r\n",
                "\r\n",
                "dependenciesUrl = edfi_api_manager.dependencies_url\r\n",
                "openApiMetadataUrl = edfi_api_manager.openapi_metadata_url\r\n",
                "dataManagementUrl = edfi_api_manager.data_management_url\r\n",
                "authUrl = edfi_api_manager.auth_url\r\n",
                "\r\n",
                "changeQueriesUrl = edfi_api_manager.get_referenced_url('Change-Queries')\r\n",
                "changeQueriesUrl = changeQueriesUrl[:-13].replace('/metadata/', '/')\r\n",
                "swagger_url = swaggerUrl = edfi_api_manager.get_referenced_url('Resources')\r\n",
                "\r\n",
                "apiVersion = edfi_api_manager.api_version\r\n",
                "apiVersion = apiVersion[1:] if apiVersion.startswith('v') else apiVersion"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "source": [
                "### OEA Initializations"
            ],
            "outputs": []
        },
        {
            "execution_count": 25,
            "cell_type": "code",
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "source": [
                "%run OEA/modules/Ed-Fi/v0.6/src/utilities/edfi_v0_6_edfi_py"
            ],
            "outputs": []
        },
        {
            "execution_count": 26,
            "cell_type": "code",
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "source": [
                "oea = EdFiOEAChild()   \r\n",
                "oea.set_workspace(workspace)"
            ],
            "outputs": []
        },
        {
            "execution_count": 27,
            "cell_type": "code",
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "source": [
                "# swagger_url = swaggerUrl = edfi_api_manager.get_referenced_url('Descriptors')\r\n",
                "oea_utils = schema_gen = OpenAPIUtil(swagger_url)\r\n",
                "oea_utils.create_definitions()\r\n",
                "schemas = schema_gen.create_spark_schemas()"
            ],
            "outputs": []
        },
        {
            "execution_count": 28,
            "cell_type": "code",
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "source": [
                "parameterized = False\r\n",
                "if parameterized == True:\r\n",
                "    edfiEntitiesPath = f'stage1/Transactional/{moduleName}/{apiVersion}/DistrictId={districtId}/SchoolYear={schoolYear}/etl_entities/current_run_data'\r\n",
                "\r\n",
                "    _, edfiEntities = edfi.listSpecifiedEntities(edfiEntitiesPath)\r\n",
                "else:\r\n",
                "    edfiEntities = \"All\"  "
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "source": [
                "### Main Code"
            ],
            "outputs": []
        },
        {
            "execution_count": 29,
            "cell_type": "code",
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "source": [
                "edfiRefineAgent = EdFiRefine(workspace = workspace, \r\n",
                "                             oea = oea, \r\n",
                "                             schema_gen = schema_gen,\r\n",
                "                             moduleName = moduleName, \r\n",
                "                             authUrl = authUrl,\r\n",
                "                             swaggerUrl = swaggerUrl, \r\n",
                "                             dataManagementUrl = dataManagementUrl, \r\n",
                "                             changeQueriesUrl = changeQueriesUrl, \r\n",
                "                             dependenciesUrl = dependenciesUrl, \r\n",
                "                             apiVersion = apiVersion, \r\n",
                "                             schoolYear = schoolYear, \r\n",
                "                             districtId = districtId,\r\n",
                "                             test_mode = False)"
            ],
            "outputs": []
        },
        {
            "execution_count": 30,
            "cell_type": "code",
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "source": [
                "def upsert_data(df_changes, \r\n",
                "                metadata,\r\n",
                "                schema_name, \r\n",
                "                transform_mode,\r\n",
                "                table_name,\r\n",
                "                primary_key,\r\n",
                "                ext_entity,\r\n",
                "                sink_general_path,\r\n",
                "                sink_sensitive_path):\r\n",
                "        df_pseudo, df_lookup = oea.pseudonymize(df_changes, \r\n",
                "                                                metadata,\r\n",
                "                                                transform_mode,\r\n",
                "                                                True)\r\n",
                "                                \r\n",
                "        edfiRefineAgent.transform(df = df_pseudo, \r\n",
                "                schema_name = schema_name, \r\n",
                "                table_name = table_name, \r\n",
                "                primary_key = 'id_pseudonym', \r\n",
                "                ext_entity = ext_entity, \r\n",
                "                sink_general_path = sink_general_path,\r\n",
                "                districtId_col_name = 'DistrictId', \r\n",
                "                schoolYear_col_name = 'SchoolYear')\r\n",
                "        if '/emptySchemas/' not in sink_sensitive_path:                \r\n",
                "                oea.upsert(df = df_lookup, \r\n",
                "                        destination_path = sink_sensitive_path, \r\n",
                "                        primary_key = 'id',\r\n",
                "                        partitioning = True,\r\n",
                "                        partitioning_cols = ['DistrictId', 'SchoolYear'])    \r\n",
                "                oea.add_to_lake_db(source_entity_path = sink_sensitive_path,\r\n",
                "                                overwrite = True,\r\n",
                "                                extension = None)"
            ],
            "outputs": []
        },
        {
            "execution_count": 46,
            "cell_type": "code",
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "source": [
                "def dump_empty_schemas(schema_name, \r\n",
                "                       s2r_path,\r\n",
                "                       ext_entity,\r\n",
                "                       transform_mode, \r\n",
                "                       items = []):\r\n",
                "    global districtId,schoolYear\r\n",
                "    if schema_name is None:\r\n",
                "        schema_name = 'ed-fi'\r\n",
                "    \r\n",
                "    for item in items:\r\n",
                "        table_name = item #sap_to_edfi_complex[item]\r\n",
                "        schema_name_temp = schema_name\r\n",
                "        try:\r\n",
                "            if item.lower().endswith('exts'):\r\n",
                "                # FIXME: Temporary Fix\r\n",
                "                schema_name = 'tx'\r\n",
                "            logger.info('Path does not exist - attempting to create empty data frame')                        \r\n",
                "            sink_general_path = f'{s2r_path}/general/{schema_name}/{item}'\r\n",
                "            sink_sensitive_path = f'{s2r_path}/sensitive/{schema_name}/{item}_lookup'\r\n",
                "                            \r\n",
                "            sink_general_path = edfiRefineAgent.sink_path_cleanup(sink_general_path)\r\n",
                "            sink_sensitive_path = edfiRefineAgent.sink_path_cleanup(sink_sensitive_path)\r\n",
                "            if oea.path_exists(sink_general_path):\r\n",
                "                continue\r\n",
                "                        \r\n",
                "            target_schema = copy.deepcopy(edfiRefineAgent.schemas[table_name])    \r\n",
                "            df_changes = spark.createDataFrame(data = [],\r\n",
                "                                               schema = target_schema)\r\n",
                "            df_changes = df_changes.withColumn('DistrictId', F.lit(districtId))\r\n",
                "            df_changes = df_changes.withColumn('SchoolYear', F.lit(schoolYear))\r\n",
                "            \r\n",
                "            current_timestamp = datetime.now()\r\n",
                "            df_changes = df_changes.withColumn('LastModifiedDate', F.lit(current_timestamp))\r\n",
                "            df_changes = df_changes.withColumn('rowIsActive', F.lit(True))\r\n",
                "                            \r\n",
                "\r\n",
                "            if 'id' in df_changes.columns:\r\n",
                "                upsert_data(df_changes, \r\n",
                "                            metadata,\r\n",
                "                            schema_name, \r\n",
                "                            transform_mode,\r\n",
                "                            table_name,\r\n",
                "                            'id',\r\n",
                "                            ext_entity,\r\n",
                "                            sink_general_path,\r\n",
                "                            sink_sensitive_path)\r\n",
                "            else:\r\n",
                "                logger.info(f'{item} does not have id as primary key - flagged for future')\r\n",
                "        except Exception as error:\r\n",
                "            logger.info(f\"Error - {error}\")\r\n",
                "        schema_name = schema_name_temp\r\n",
                "\r\n",
                "def refine_and_explode_data(schema_name, \r\n",
                "                            tables_source,\r\n",
                "                            ext_entity,\r\n",
                "                            metadata, \r\n",
                "                            transform_mode, \r\n",
                "                            test_mode,\r\n",
                "                            items = []):\r\n",
                "    global districtId,schoolYear\r\n",
                "    if items == 'All':\r\n",
                "        items = oea.get_folders(f\"stage2/Ingested/{tables_source}\")\r\n",
                "        items.append('schoolYearTypes')\r\n",
                "    #items = ['accountCodes', 'accounts', 'grades', 'students', 'staffs']\r\n",
                "    #items = items[:50]\r\n",
                "    for item in items:\r\n",
                "            table_name = item #sap_to_edfi_complex[item]\r\n",
                "            table_path = f\"{tables_source}/{item}\"\r\n",
                "            logger.info(f\"Processing schema/table: {schema_name}/{table_name}\")\r\n",
                "            if item == 'metadata.csv':\r\n",
                "                logger.info('ignore metadata processing, since this is not a table to be ingested')\r\n",
                "            else: \r\n",
                "                try:\r\n",
                "                    if not(oea.path_exists(f\"stage2/Ingested/{table_path}\")):\r\n",
                "                        pass\r\n",
                "                    else:\r\n",
                "                        if not(transform_mode):\r\n",
                "                            df = oea.refine(table_path, \r\n",
                "                                            metadata = metadata[item], \r\n",
                "                                            primary_key = 'id')\r\n",
                "                        if transform_mode:\r\n",
                "                            logger.info('Ed-Fi to Ed-Fi Relationship Model: ' + table_name)               \r\n",
                "                            source_path = f'stage2/Ingested/{table_path}'\r\n",
                "                            sink_general_path, sink_sensitive_path = oea.get_sink_general_sensitive_paths(source_path)\r\n",
                "                            \r\n",
                "                            sink_general_path = edfiRefineAgent.sink_path_cleanup(sink_general_path)\r\n",
                "                            sink_sensitive_path = edfiRefineAgent.sink_path_cleanup(sink_sensitive_path)\r\n",
                "\r\n",
                "                            df_changes = oea.get_latest_changes(source_path, sink_general_path, filtering_date = 'rundate')\r\n",
                "\r\n",
                "                            df_changes = df_changes.withColumn('DistrictId', F.lit(districtId))\r\n",
                "                            \r\n",
                "                            # FIXME TO BE REVISED\r\n",
                "                            if item != 'schoolYearTypes':\r\n",
                "                                df_changes = df_changes.withColumn('SchoolYear', F.lit(schoolYear))\r\n",
                "                            else:\r\n",
                "                                # df_changes = df_changes.withColumnRenamed(\"schoolYear\", \"SchoolYear\")\r\n",
                "                                pass\r\n",
                "                            \r\n",
                "                            current_timestamp = datetime.now()\r\n",
                "                            df_changes = df_changes.withColumn('LastModifiedDate', F.lit(current_timestamp))\r\n",
                "                            \r\n",
                "                            if df_changes.count() > 0:\r\n",
                "                                upsert_data(df_changes, \r\n",
                "                                            metadata,\r\n",
                "                                            schema_name, \r\n",
                "                                            transform_mode,\r\n",
                "                                            table_name,\r\n",
                "                                            'id_pseudonym',\r\n",
                "                                            ext_entity,\r\n",
                "                                            sink_general_path,\r\n",
                "                                            sink_sensitive_path)\r\n",
                "                            else:\r\n",
                "                                logger.info(f'No updated rows in {source_path} to process.')\r\n",
                "\r\n",
                "                except AnalysisException as e:\r\n",
                "                    # This means the table may have not been properly refined due to errors with the primary key not aligning with columns expected in the lookup table.\r\n",
                "                    logger.info(e)\r\n",
                "\r\n",
                "def get_non_ext_entities(entities_meta_info):\r\n",
                "    non_ext_table_names = list()\r\n",
                "    for entity_meta_info in entities_meta_info:\r\n",
                "        non_ext_table_names.append(entity_meta_info['resource'].split('/')[-1])\r\n",
                "    return non_ext_table_names\r\n",
                "\r\n",
                "def add_all_empty_tables_to_lake_db(empty_tables_path, schema_name, emptyTables = None):\r\n",
                "    if emptyTables is None:\r\n",
                "        empty_tables_source = oea.to_url(empty_tables_path)\r\n",
                "        items = oea.get_folders(empty_tables_source)\r\n",
                "    else:\r\n",
                "        items = emptyTables\r\n",
                "    if schema_name == 'ed-fi':\r\n",
                "        extension = None\r\n",
                "    else:\r\n",
                "        extension = schema_name  \r\n",
                "    for item in items:\r\n",
                "        source_entity_path = empty_tables_path + '/' + item \r\n",
                "        add_empty_table_to_lake_db(source_entity_path, \r\n",
                "                                  overwrite = False, \r\n",
                "                                  extension = extension)\r\n",
                "\r\n",
                "def add_empty_table_to_lake_db(source_entity_path, overwrite = False, extension = None):\r\n",
                "        # FIXME: Temporary Fix for Empty Schemas\r\n",
                "        \"\"\" Adds the given entity as a table (if the table doesn't already exist) to the proper lake db based on the path.\r\n",
                "            This method will also create the lake db if it doesn't already exist.\r\n",
                "            eg: add_to_lake_db('stage2/Ingested/contoso_sis/v0.2/students')\r\n",
                "\r\n",
                "            Note that a spark db that points to source data in the delta format can't be queried via SQL serverless pool. More info here: https://docs.microsoft.com/en-us/azure/synapse-analytics/sql/resources-self-help-sql-on-demand#delta-lake\r\n",
                "        \"\"\"\r\n",
                "        source_dict = oea.parse_path(source_entity_path)\r\n",
                "        if '/emptySchemas/' in source_entity_path:\r\n",
                "            try:\r\n",
                "                base_db_name = source_dict['ldb_name']\r\n",
                "                base_table_name = source_dict['entity']\r\n",
                "                for submission_type in ['']:     \r\n",
                "                    if extension is not None:\r\n",
                "                        if not(extension.startswith('_')):\r\n",
                "                            extension = '_' + extension\r\n",
                "                        source_dict['entity'] = base_table_name + str(extension)\r\n",
                "                    \r\n",
                "                    db_name = base_db_name + submission_type\r\n",
                "\r\n",
                "                    logger.info(f\"Adding: Lake DB: {db_name}; Table: {source_dict['entity']}\")\r\n",
                "                    spark.sql(f'CREATE DATABASE IF NOT EXISTS {db_name}')\r\n",
                "                    if overwrite:\r\n",
                "                        spark.sql(f\"drop table if exists {db_name}.{source_dict['entity']}\")\r\n",
                "\r\n",
                "                    spark.sql(f\"create table if not exists {db_name}.{source_dict['entity']} using DELTA location '{oea.to_url(source_dict['entity_path'])}'\")\r\n",
                "            except Exception as error:\r\n",
                "                logger.error(f'An error occured - {error}')"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "source": [
                "from datetime import datetime\r\n",
                "import math\r\n",
                "source_path = f'stage1/Transactional/Ed-Fi/{apiVersion}/DistrictId={districtId}/SchoolYear={schoolYear}/metadata-assets/frequency_etl.csv'  \r\n",
                "destination_path = source_path #f'stage1/Transactional/Ed-Fi/{apiVersion}/DistrictId={districtId}/SchoolYear={schoolYear}/metadata-assets/frequency_based_etl.csv'  \r\n",
                "logs_path = f\"stage1/Transactional/Ed-Fi/{apiVersion}/DistrictId={districtId}/SchoolYear={schoolYear}/metadata-assets/_frequency_etl_logs/run_logs_{datetime.today().strftime('%Y-%m-%d')}.csv\"\r\n",
                "\r\n",
                "processor = EntityFrequencyProcessor(oea = oea, \r\n",
                "                                     filepath = source_path, \r\n",
                "                                     highFrequentDelta = highFrequentDelta,#0.005, \r\n",
                "                                     moderateFrequentDelta = moderateFrequentDelta, #5, \r\n",
                "                                     lowFrequentDelta = lowFrequentDelta, #10, \r\n",
                "                                     descriptorsDelta = descriptorsDelta) #360)\r\n",
                "\r\n",
                "processor.load_lookup_df()\r\n",
                "_, entities_to_etl = processor.return_entities_to_etl()\r\n",
                "\r\n",
                "logger.info(entities_to_etl)\r\n",
                "\r\n",
                "edfiEntities = \"All\" #['schoolYearTypes']\r\n",
                "tpdmEntities = 'All'\r\n",
                "\r\n",
                "edfiEntities = entities_to_etl.get('ed-fi', [])\r\n",
                "tpdmEntities = entities_to_etl.get('tpdm', [])"
            ],
            "outputs": []
        },
        {
            "execution_count": 32,
            "cell_type": "code",
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "source": [
                "from datetime import datetime\r\n",
                "schema_name = 'ed-fi'\r\n",
                "ext_entity = 'TPDM'\r\n",
                "test_mode = False\r\n",
                "transform_mode = True\r\n",
                "tables_source = f'{moduleName}/{apiVersion}/DistrictId={districtId}/SchoolYear={schoolYear}/{schema_name}'\r\n",
                "transform_items = edfiEntities#\"All\" #non_ext_table_names#edfiEntities \r\n",
                "\r\n",
                "# Create or overwrite Metadata.csv\r\n",
                "metadataPath = f'stage1/Transactional/Ed-Fi/{apiVersion}/DistrictId={districtId}/SchoolYear={schoolYear}/metadata-assets'\r\n",
                "metadata = oea.get_metadata_from_path(metadataPath) # metadata = oea.get_metadata_from_url(metadataUrl)"
            ],
            "outputs": []
        },
        {
            "execution_count": 33,
            "cell_type": "code",
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "source": [
                "df = refine_and_explode_data(schema_name, \r\n",
                "                        tables_source,\r\n",
                "                        ext_entity,\r\n",
                "                        metadata,\r\n",
                "                        transform_mode, \r\n",
                "                        test_mode,\r\n",
                "                        transform_items)"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "source": [
                "### Empty Schemas"
            ],
            "outputs": []
        },
        {
            "execution_count": 34,
            "cell_type": "code",
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "source": [
                "from datetime import datetime\r\n",
                "transform_mode = True\r\n",
                "\r\n",
                "if prepareEdFiMetaData:\r\n",
                "    edfiAPIClient = EdFiClient(workspace = workspace, \r\n",
                "                                    kvName = kvName, #NOTE: Default to None \r\n",
                "                                    moduleName = moduleName, \r\n",
                "                                    authUrl = authUrl, \r\n",
                "                                    dataManagementUrl = dataManagementUrl, \r\n",
                "                                    changeQueriesUrl = changeQueriesUrl, \r\n",
                "                                    dependenciesUrl = dependenciesUrl, \r\n",
                "                                    apiVersion = apiVersion, \r\n",
                "                                    batchLimit = batchLimit, \r\n",
                "                                    minChangeVer = minChangeVer, \r\n",
                "                                    maxChangeVer = maxChangeVer,\r\n",
                "                                    schoolYear = schoolYear,\r\n",
                "                                    districtId = districtId,\r\n",
                "                                    clientId = client_id,\r\n",
                "                                    clientSecret = client_secret_id)\r\n",
                "\r\n",
                "    entities_meta_info = edfiAPIClient.getEntities()#[0]['resource']\r\n",
                "    non_ext_table_names = get_non_ext_entities(entities_meta_info) #TODO: To Be Reviewed\r\n",
                "    non_ext_table_names = ['schoolYearTypes'] + non_ext_table_names\r\n",
                "\r\n",
                "    for swagger_resource_type in ['Resources', 'Descriptors']:\r\n",
                "        swagger_url = swaggerUrl = edfi_api_manager.get_referenced_url(swagger_resource_type)\r\n",
                "        oea_utils = schema_gen = OpenAPIUtil(swagger_url)\r\n",
                "        oea_utils.create_definitions()\r\n",
                "        schemas = schema_gen.create_spark_schemas()\r\n",
                "\r\n",
                "        \r\n",
                "        edfiRefineAgent = EdFiRefine(workspace = workspace, \r\n",
                "                             oea = oea, \r\n",
                "                             schema_gen = schema_gen,\r\n",
                "                             moduleName = moduleName, \r\n",
                "                             authUrl = authUrl,\r\n",
                "                             swaggerUrl = swaggerUrl, \r\n",
                "                             dataManagementUrl = dataManagementUrl, \r\n",
                "                             changeQueriesUrl = changeQueriesUrl, \r\n",
                "                             dependenciesUrl = dependenciesUrl, \r\n",
                "                             apiVersion = apiVersion, \r\n",
                "                             schoolYear = schoolYear, \r\n",
                "                             districtId = districtId,\r\n",
                "                             test_mode = False)\r\n",
                "\r\n",
                "        # non_ext_table_names = sap_to_edfi_client.return_non_ext_tables()  \r\n",
                "        if swagger_resource_type == 'Resources':\r\n",
                "            transform_items = [item for item in non_ext_table_names if not(item.lower().endswith('descriptors'))]\r\n",
                "        elif swagger_resource_type == 'Descriptors':\r\n",
                "            transform_items = [item for item in non_ext_table_names if item.lower().endswith('descriptors')]\r\n",
                "      \r\n",
                "        s2r_path = f'stage2/Refined/Ed-Fi/{apiVersion}/emptySchemas'\r\n",
                "\r\n",
                "        dump_empty_schemas(schema_name = schema_name , \r\n",
                "                        s2r_path = s2r_path,\r\n",
                "                        ext_entity = ext_entity,\r\n",
                "                        transform_mode = transform_mode, \r\n",
                "                        items = transform_items)"
            ],
            "outputs": []
        },
        {
            "execution_count": 47,
            "cell_type": "code",
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "source": [
                "if prepareEdFiMetadata:\r\n",
                "    tables_source = f'Ed-Fi/{apiVersion}/ed-fi'\r\n",
                "    mainTables = [item for item in oea.get_folders(f\"stage2/Refined/{tables_source}/general\") if item != 'descriptorTables']\r\n",
                "\r\n",
                "    tables_source = f'Ed-Fi/{apiVersion}/{ext_entity.lower()}'\r\n",
                "    extTables = [item for item in oea.get_folders(f\"stage2/Refined/{tables_source}/general\") if item != 'descriptorTables']\r\n",
                "    if extTables != []:\r\n",
                "        mainTables = mainTables + extTables\r\n",
                "    edfi_emptyTables = oea.get_folders(f'stage2/Refined/Ed-Fi/{apiVersion}/emptySchemas/general/ed-fi')\r\n",
                "    edfi_emptyTables = edfiRefineAgent.non_empty_elements(edfi_emptyTables, \r\n",
                "                                                             mainTables)\r\n",
                "    ext_emptyTables = oea.get_folders(f'stage2/Refined/Ed-Fi/{apiVersion}/emptySchemas/general/{ext_entity.lower()}')\r\n",
                "    ext_emptyTables = edfiRefineAgent.non_empty_elements(ext_emptyTables, \r\n",
                "                                                             mainTables)\r\n",
                "\r\n",
                "    emptyTables_path = f'stage2/Refined/Ed-Fi/{apiVersion}/emptySchemas/general/ed-fi'\r\n",
                "    if edfi_emptyTables != list():\r\n",
                "        add_all_empty_tables_to_lake_db(emptyTables_path, 'ed-fi', edfi_emptyTables)\r\n",
                "\r\n",
                "    emptyTables_path = f'stage2/Refined/Ed-Fi/{apiVersion}/emptySchemas/general/{ext_entity.lower()}'\r\n",
                "    if ext_emptyTables != list():\r\n",
                "        add_all_empty_tables_to_lake_db(emptyTables_path, 'tpdm', ext_emptyTables)"
            ],
            "outputs": []
        }
    ]
}